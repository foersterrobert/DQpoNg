{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5QtiPS247g-"
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import random\n",
        "from math import cos, sin, radians\n",
        "from collections import deque\n",
        "import itertools"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L09Zvj-5Dn6",
        "outputId": "fd74ff1b-9307-47cc-91fa-8fd97b6422d4"
      },
      "source": [
        "# Params\n",
        "N_FRAMES = 2\n",
        "GAMMA = 0.95\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.00025\n",
        "MAX_MEMORY = 200_000\n",
        "MIN_REPLAY_SIZE = 100_000 * N_FRAMES\n",
        "EPSILON_START = 1.0\n",
        "EPSILON_END = 0.02\n",
        "EPSILON_DECAY = 50000 * N_FRAMES\n",
        "TARGET_UPDATE_FREQ = 10000 * N_FRAMES\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Autp49Z-5fYA"
      },
      "source": [
        "class Game:\n",
        "    def __init__(self, play, train):\n",
        "        self.play = play\n",
        "        self.train = train\n",
        "        if self.play:\n",
        "            pygame.init()\n",
        "            pygame.display.set_caption('Pong')\n",
        "            pygame.display.set_icon(pygame.image.load('assets/icon.png'))\n",
        "            self.myFont = pygame.font.SysFont('arial', 30)\n",
        "            self.screen = pygame.display.set_mode((640, 480))\n",
        "            self.clock = pygame.time.Clock()\n",
        "        else:\n",
        "            self.screen = None\n",
        "\n",
        "        self.player1 = Paddle(self.screen, 5, [-45, -30, -15, -10, 10, 15, 30, 45])\n",
        "        self.player2 = Paddle(self.screen, 625, [225, 210, 195, 190, 170, 165, 150, 135]) # 135 -> 225 | 180 + (180 - x)\n",
        "        self.ball = Ball(self.screen)\n",
        "\n",
        "    def update(self):\n",
        "        self.player1.update()\n",
        "        self.player2.update()\n",
        "        reward, done = self.ball.update(self.player1, self.player2, self.train)\n",
        "        return reward, done\n",
        "\n",
        "    def render(self):\n",
        "        self.screen.fill((0, 0, 0))\n",
        "        self.player1.render()\n",
        "        self.player2.render()\n",
        "        self.ball.render()\n",
        "        textSurface = self.myFont.render(f'AI {self.player1.score}:{self.player2.score} YOU', False, (255, 255, 255))\n",
        "        self.screen.blit(textSurface, (250, 20))\n",
        "        pygame.display.flip()\n",
        "\n",
        "    def getState(self):\n",
        "        state = [\n",
        "                round(self.player1.y / (480 - self.player1.height), 2),\n",
        "                round(self.player2.y / (480 - self.player2.height), 2),\n",
        "                round(self.ball.y / 480, 2),\n",
        "                round(self.ball.x / 640, 2),\n",
        "                round(self.ball.angle / 255, 2),\n",
        "        ]\n",
        "        return np.array(state, dtype=np.float)\n",
        "\n",
        "    def run(self):\n",
        "        reward, done = self.update()\n",
        "        if self.play:\n",
        "            self.render()\n",
        "            self.clock.tick(60)\n",
        "        return reward, done\n",
        "\n",
        "class Ball:\n",
        "    def __init__(self, screen):\n",
        "        self.screen = screen\n",
        "        self.frame = 0\n",
        "        self.x = 320\n",
        "        self.y = 240\n",
        "        self.angle = random.choice([-45, -30, -15, -10, 10, 15, 30, 45]) + 180 * random.randint(0, 1)\n",
        "        self.speed = 8\n",
        "        self.radius = 6\n",
        "\n",
        "    def update(self, player1, player2, train):\n",
        "        reward = 0\n",
        "        done = False\n",
        "        if train:\n",
        "            self.frame += 1\n",
        "        \n",
        "        # Check if ball hits the top or bottom\n",
        "        if self.y + self.radius > 480 or self.y - self.radius < 0:\n",
        "            if self.angle <= 45:\n",
        "                self.angle = -self.angle\n",
        "            else:\n",
        "                self.angle = 360 - self.angle\n",
        "\n",
        "        # left collide\n",
        "        if self.x - self.radius >= player1.x and self.x - self.radius <= player1.x + player1.width:\n",
        "            if self.y - player1.y >= -self.radius:\n",
        "                for i in range(len(player1.angles)):\n",
        "                    if self.y - player1.y <= (i+1)/len(player1.angles) * (player1.height + self.radius):\n",
        "                        self.angle = player1.angles[i]\n",
        "                        break\n",
        "                reward = 2\n",
        "\n",
        "        # right collide\n",
        "        elif self.x + self.radius >= player2.x and self.x + self.radius <= player2.x + player2.width:\n",
        "            if self.y - player2.y >= -self.radius:\n",
        "                for i in range(len(player2.angles)):\n",
        "                    if self.y - player2.y <= (i+1)/len(player2.angles) * (player2.height + self.radius):\n",
        "                        self.angle = player2.angles[i]\n",
        "                        break\n",
        "\n",
        "        self.y += self.speed*sin(radians(self.angle))\n",
        "        self.x += self.speed*cos(radians(self.angle))\n",
        "\n",
        "        # Check if the Ball went right\n",
        "        if self.x - self.radius >= 670:\n",
        "            player1.score += 1\n",
        "            reward = 10\n",
        "            self.x = player2.x - player2.width * 2 - self.radius\n",
        "            self.y = 240\n",
        "            self.angle = random.choice(player2.angles[2:-2])\n",
        "            self.frame = 0\n",
        "        \n",
        "        # Check if the Ball went left\n",
        "        if self.x + self.radius <= -30 or self.frame > 1000:\n",
        "            player2.score += 1\n",
        "            reward = -10\n",
        "            if player2.score % 5 == 0:\n",
        "                done = True\n",
        "            self.x = player1.x + player1.width * 2 + self.radius\n",
        "            self.y = 240\n",
        "            self.angle = random.choice(player1.angles[2:-2])\n",
        "            self.frame = 0\n",
        "\n",
        "        return reward, done\n",
        "\n",
        "    def render(self):\n",
        "        pygame.draw.circle(self.screen, (255, 255, 255), (self.x, self.y), self.radius)\n",
        "\n",
        "class Paddle:\n",
        "    def __init__(self, screen, x, angles):\n",
        "        self.angles = angles\n",
        "        self.screen = screen\n",
        "        self.x = x\n",
        "        self.speed = 4\n",
        "        self.width = 10\n",
        "        self.height = 80\n",
        "        self.y = 240 - self.height / 2\n",
        "        self.score = 0\n",
        "        self.mode = 0\n",
        "\n",
        "    def update(self):\n",
        "        self.y += self.mode * self.speed\n",
        "        self.y = max(0, min(self.y, 480 - self.height))\n",
        "\n",
        "    def render(self):\n",
        "        pygame.draw.rect(self.screen, (255, 255, 255), (self.x, self.y, self.width, self.height))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0i36yx05MYp"
      },
      "source": [
        "# DQN\n",
        "class Linear_QNet(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(input_size, 128)\n",
        "        self.linear2 = nn.Linear(128, 256)\n",
        "        self.linear3 = nn.Linear(256, 1024)\n",
        "        self.linear4 = nn.Linear(1024, 256)\n",
        "        self.linear5 = nn.Linear(256, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        x = F.relu(self.linear4(x))\n",
        "        x = self.linear5(x)\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.online_net = Linear_QNet(5, 2).to(DEVICE)\n",
        "        self.target_net = Linear_QNet(5, 2).to(DEVICE)\n",
        "        self.target_net.load_state_dict(self.online_net.state_dict())\n",
        "        self.memory = deque(maxlen=MAX_MEMORY)\n",
        "        self.optimizer = optim.Adam(self.online_net.parameters(), lr=LEARNING_RATE)\n",
        "        self.record = -50\n",
        "        self.score = 0\n",
        "\n",
        "    def get_action(self, state, step):\n",
        "        if step + 1:\n",
        "            epsilon = np.interp(step - MIN_REPLAY_SIZE, [0, EPSILON_DECAY], [EPSILON_START, EPSILON_END])\n",
        "        else:\n",
        "            epsilon = 0\n",
        "        if random.random() <= epsilon:\n",
        "            action = random.randint(0, 1)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                state_t = torch.as_tensor(state, dtype=torch.float32, device=DEVICE)\n",
        "                q_values = self.online_net(state_t.unsqueeze(0))\n",
        "                max_q_index = torch.argmax(q_values, dim=1)[0]\n",
        "                action = max_q_index.detach().item()\n",
        "        return action\n",
        "\n",
        "    def train(self, state_old, action, reward, done, state_new, step):\n",
        "        self.memory.append((state_old, action, reward, done, state_new))\n",
        "        if len(self.memory) > MIN_REPLAY_SIZE:\n",
        "            self.score += reward\n",
        "            transitions = random.sample(self.memory, BATCH_SIZE)\n",
        "\n",
        "            state_olds = np.asarray([t[0] for t in transitions])\n",
        "            actions = np.asarray([t[1] for t in transitions])\n",
        "            rewards = np.asarray([t[2] for t in transitions])\n",
        "            dones = np.asarray([t[3] for t in transitions])\n",
        "            state_news = np.asarray([t[4] for t in transitions])\n",
        "\n",
        "            obses_t = torch.as_tensor(state_olds, dtype=torch.float32, device=DEVICE)\n",
        "            actions_t = torch.as_tensor(actions, dtype=torch.int64, device=DEVICE).unsqueeze(-1)\n",
        "            rews_t = torch.as_tensor(rewards, dtype=torch.float32, device=DEVICE).unsqueeze(-1)\n",
        "            dones_t = torch.as_tensor(dones, dtype=torch.float32, device=DEVICE).unsqueeze(-1)\n",
        "            new_obses_t = torch.as_tensor(state_news, dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "            # Compute Targets\n",
        "            # double q learning later\n",
        "            target_q_values = self.target_net(new_obses_t)\n",
        "            max_target_q_values = target_q_values.max(\n",
        "                dim=1, keepdim=True)[0]\n",
        "            targets = rews_t + GAMMA * \\\n",
        "                (1 - dones_t) * max_target_q_values\n",
        "\n",
        "            # Compute Loss\n",
        "            q_values = self.online_net(obses_t)\n",
        "            action_q_values = torch.gather(\n",
        "                input=q_values, dim=1, index=actions_t)\n",
        "            loss = nn.functional.smooth_l1_loss(\n",
        "                action_q_values, targets)\n",
        "\n",
        "            # Gradient Descent\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # Update Target Net\n",
        "            if max(-1, step - MIN_REPLAY_SIZE) % TARGET_UPDATE_FREQ == 0:\n",
        "                print(step)\n",
        "                self.target_net.load_state_dict(self.online_net.state_dict())\n",
        "\n",
        "            if done:\n",
        "                if self.score > self.record:\n",
        "                    self.record = self.score\n",
        "                    print('Record:', self.record, 'Step:', step)\n",
        "                    self.save()\n",
        "                self.score = 0\n",
        "\n",
        "    def load(self, name):\n",
        "        self.online_net.load_state_dict(torch.load(f'model/{name}.pth', map_location=DEVICE))\n",
        "\n",
        "    def save(self, file_name='model.pth'):\n",
        "        model_folder_path = './model'\n",
        "        if not os.path.exists(model_folder_path):\n",
        "            os.makedirs(model_folder_path)\n",
        "        file_name = os.path.join(model_folder_path, file_name)\n",
        "        torch.save(self.online_net.state_dict(), file_name)"
      ],
      "metadata": {
        "id": "zm-Zefo92xsb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4A1ZugK5TZJ"
      },
      "source": [
        "def human_action(game):\n",
        "    for event in pygame.event.get():\n",
        "        if event.type == pygame.KEYDOWN:\n",
        "            if event.key == pygame.K_UP:\n",
        "                game.player2.mode = -1\n",
        "            if event.key == pygame.K_DOWN:\n",
        "                game.player2.mode = 1\n",
        "        if event.type == pygame.QUIT:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def bot_action(game):\n",
        "        if game.ball.y < game.player2.y + game.player2.height/2:\n",
        "            game.player2.mode = -1\n",
        "        elif game.ball.y > game.player2.y - game.player2.height/2:\n",
        "            game.player2.mode = 1\n",
        "\n",
        "def main(args):\n",
        "    game = Game(args['see'], args['train'])\n",
        "    player1 = Agent()\n",
        "    if args['load']:\n",
        "        player1.load('model')\n",
        "    run = True\n",
        "    for frame in itertools.count():\n",
        "        if not run:\n",
        "            break\n",
        "        if args['bot']:\n",
        "            bot_action(game)\n",
        "        elif args['human']:\n",
        "            run = human_action(game)\n",
        "        if frame % N_FRAMES == 0:\n",
        "            state_old = game.getState()\n",
        "            action = player1.get_action(state_old, frame/N_FRAMES if args['train'] else -1)\n",
        "            if action == 0:\n",
        "                game.player1.mode = -1\n",
        "            else:\n",
        "                game.player1.mode = 1\n",
        "            reward, done = game.run()\n",
        "            if args['train']:\n",
        "                state_new = game.getState()\n",
        "                player1.train(state_old, action, reward, done, state_new, frame/N_FRAMES)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il7W0Wwn6TJ6",
        "outputId": "6f8485d9-ebab-4125-fe1b-32d8541bcea6"
      },
      "source": [
        "main({'see': False, 'human': False, 'bot': True, 'selfPlay': False, 'load': False, 'train': True})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100000.0\n",
            "Record: -10 Step: 100256.0\n"
          ]
        }
      ]
    }
  ]
}